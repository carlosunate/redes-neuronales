{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "Gy-czS6XwF7C",
        "outputId": "72250bba-05f8-445e-a585-68ed9355fc26"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div align=\"center\" \n",
              "     style=\"color: CornSilk; \n",
              "            background-color: #2e2e2e; \n",
              "            padding: 20px; \n",
              "            border-radius: 10px; \n",
              "            font-family: Arial, sans-serif; \n",
              "            line-height: 1.6;\">\n",
              "\n",
              "  <h1 style=\"margin: 0;\">Redes Neuronales y Aprendizaje Profundo</h1>\n",
              "\n",
              "  <h3 style=\"margin-top: 10px; margin-bottom: 20px;\">\n",
              "    Máster Universitario en Inteligencia Artificial\n",
              "  </h3>\n",
              "\n",
              "  <p style=\"margin: 5px 0;\">\n",
              "    <strong>Universidad Internacional de La Rioja (UNIR)</strong>\n",
              "  </p>\n",
              "  <p style=\"margin: 5px 0;\">\n",
              "    <strong>Profesor:</strong> Pablo Negre\n",
              "  </p>\n",
              "\n",
              "  <hr style=\"border: 1px solid CornSilk; width: 80%; margin-top: 20px;\">\n",
              "</div>\n",
              "\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%%html\n",
        "<div align=\"center\"\n",
        "     style=\"color: CornSilk;\n",
        "            background-color: #2e2e2e;\n",
        "            padding: 20px;\n",
        "            border-radius: 10px;\n",
        "            font-family: Arial, sans-serif;\n",
        "            line-height: 1.6;\">\n",
        "\n",
        "  <h1 style=\"margin: 0;\">Redes Neuronales y Aprendizaje Profundo</h1>\n",
        "\n",
        "  <h3 style=\"margin-top: 10px; margin-bottom: 20px;\">\n",
        "    Máster Universitario en Inteligencia Artificial\n",
        "  </h3>\n",
        "\n",
        "  <p style=\"margin: 5px 0;\">\n",
        "    <strong>Universidad Internacional de La Rioja (UNIR)</strong>\n",
        "  </p>\n",
        "  <p style=\"margin: 5px 0;\">\n",
        "    <strong>Profesor:</strong> Pablo Negre\n",
        "  </p>\n",
        "\n",
        "  <hr style=\"border: 1px solid CornSilk; width: 80%; margin-top: 20px;\">\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# Clasificador sencillo con TensorFlow/Keras\n",
        "# ===============================================\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# 1. Cargar dataset MNIST directamente desde Keras\n",
        "# Son imágenes de 28x28 píxeles de dígitos (0–9)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# 2. Preprocesamiento:\n",
        "#   - Normalizamos los píxeles a [0,1] dividiendo entre 255\n",
        "#   - \"aplanamos\" cada imagen de 28x28 = 784 valores\n",
        "x_train = x_train.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
        "\n",
        "# 3. Definir el modelo secuencial con capas densas\n",
        "#   - 2 capas ocultas con ReLU\n",
        "#   - Capa de salida con softmax para clasificación multiclase (10 clases)\n",
        "model = models.Sequential([\n",
        "    layers.Dense(128, activation=\"relu\", input_shape=(784,)),  # Capa oculta 1\n",
        "    layers.Dense(64, activation=\"relu\"),                       # Capa oculta 2\n",
        "    layers.Dense(10, activation=\"softmax\")                     # Capa de salida\n",
        "])\n",
        "\n",
        "# 4. Compilar el modelo\n",
        "#   - Optimizador Adam\n",
        "#   - Pérdida de entropía cruzada categórica (para clasificación multiclase)\n",
        "#   - Métrica: exactitud\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# 5. Entrenamiento\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# 6. Evaluación en el set de prueba\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Exactitud en test (TensorFlow): {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUdiIm6swazk",
        "outputId": "0c5b7594-cfa7-4cc6-ddc2-1b5fd3105390"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8693 - loss: 0.4452 - val_accuracy: 0.9693 - val_loss: 0.1054\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9658 - loss: 0.1111 - val_accuracy: 0.9725 - val_loss: 0.0912\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9773 - loss: 0.0715 - val_accuracy: 0.9722 - val_loss: 0.0893\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9843 - loss: 0.0514 - val_accuracy: 0.9747 - val_loss: 0.0854\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9859 - loss: 0.0441 - val_accuracy: 0.9770 - val_loss: 0.0777\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.9765 - loss: 0.0860\n",
            "Exactitud en test (TensorFlow): 0.9765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# Clasificador sencillo con PyTorch\n",
        "# ===============================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 1. Transformaciones para el dataset\n",
        "#   - Convertimos a tensor\n",
        "#   - Normalizamos los valores de píxeles a [0,1]\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.view(-1))  # Aplana la imagen de 28x28 -> vector de 784\n",
        "])\n",
        "\n",
        "# 2. Descargar y cargar dataset\n",
        "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# 3. Definir la red neuronal\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)   # Capa oculta 1\n",
        "        self.fc2 = nn.Linear(128, 64)    # Capa oculta 2\n",
        "        self.fc3 = nn.Linear(64, 10)     # Capa de salida\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))      # ReLU en la primera capa\n",
        "        x = torch.relu(self.fc2(x))      # ReLU en la segunda capa\n",
        "        x = self.fc3(x)                  # Logits sin softmax (PyTorch lo aplica en la pérdida)\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "\n",
        "# 4. Definir pérdida y optimizador\n",
        "criterion = nn.CrossEntropyLoss()        # Entropía cruzada (ya incluye softmax implícito)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# 5. Entrenamiento\n",
        "for epoch in range(5):  # 5 épocas como en Keras\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()            # Resetear gradientes\n",
        "        outputs = model(images)          # Forward pass\n",
        "        loss = criterion(outputs, labels)# Calcular pérdida\n",
        "        loss.backward()                  # Backpropagation\n",
        "        optimizer.step()                 # Actualizar pesos\n",
        "    print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")\n",
        "\n",
        "# 6. Evaluación en test\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():  # No calculamos gradientes en evaluación\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)  # Elegir la clase con mayor probabilidad\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Exactitud en test (PyTorch): {correct/total:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erOPzPA5wcLu",
        "outputId": "1f1a8797-77b7-445c-b138-785907deb9b4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 58.4MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.66MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.1MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.52MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 0.3008\n",
            "Epoch 2: Loss = 0.0124\n",
            "Epoch 3: Loss = 0.0427\n",
            "Epoch 4: Loss = 0.0908\n",
            "Epoch 5: Loss = 0.0168\n",
            "Exactitud en test (PyTorch): 0.9750\n"
          ]
        }
      ]
    }
  ]
}